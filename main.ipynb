{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Importing Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "import os\n",
    "import webbrowser\n",
    "import pytube\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating Dataset\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Creating directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('data', exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Creating Word List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "words_path = os.path.join('data', 'words.csv')\n",
    "df = pd.DataFrame({'word': word_list})\n",
    "df.to_csv(words_path, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Youtube Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_youtube_videos(query):\n",
    "    api_key = os.environ.get(\"YOUTUBE_API_KEY\")\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "    video_links = []\n",
    "    video_ids = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        search_response = youtube.search().list(\n",
    "            q=query,\n",
    "            type='video',\n",
    "            part='id',\n",
    "            maxResults=50,\n",
    "            pageToken=next_page_token\n",
    "        ).execute()\n",
    "\n",
    "        for item in search_response['items']:\n",
    "            video_links.append(\n",
    "                'https://www.youtube.com/watch?v=' + item['id']['videoId'])\n",
    "            video_ids.append(item['id']['videoId'])\n",
    "\n",
    "        next_page_token = search_response.get('nextPageToken')\n",
    "\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    df = pd.DataFrame({'link': video_links, 'id': video_ids})\n",
    "    p = os.path.join('data', query + '.csv')\n",
    "    df.to_csv(p, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = pd.read_csv(words_path)\n",
    "wd = wd['word'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in wd:\n",
    "    scrape_youtube_videos(word)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Creating Unique Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in wd:\n",
    "    p = os.path.join('data', word + '.csv')\n",
    "    if os.path.exists(p):\n",
    "        df = pd.read_csv(p)\n",
    "        p2 = os.path.join('data', 'links.csv')\n",
    "        df.to_csv(p2, mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/links.csv')\n",
    "df.columns = ['index','link', 'id']\n",
    "df.to_csv('data/links.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/links.csv')\n",
    "df = df.drop('index', axis=1)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id = df['id']\n",
    "video_id = video_id.sample(5)\n",
    "# video_id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualizing Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1  Playing Video in Browser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_youtube_video(video_id):\n",
    "    for id in video_id:\n",
    "        url = f\"https://www.youtube.com/watch?v={id}\"\n",
    "        webbrowser.open(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_youtube_video(video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the YouTube video URL\n",
    "video_url = \"https://www.youtube.com/watch?v=VIDEO_ID\"\n",
    "\n",
    "# Create a YouTube object\n",
    "yt = pytube.YouTube(video_url)\n",
    "\n",
    "# Get the thumbnail URL of the video\n",
    "thumbnail_url = yt.thumbnail_url\n",
    "\n",
    "# Download the thumbnail image\n",
    "urllib.request.urlretrieve(thumbnail_url, \"thumbnail.jpg\")\n",
    "\n",
    "# Display the thumbnail image using Matplotlib\n",
    "thumbnail_image = plt.imread(\"thumbnail.jpg\")\n",
    "plt.imshow(thumbnail_image)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
